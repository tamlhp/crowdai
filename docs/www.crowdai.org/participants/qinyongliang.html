<!DOCTYPE html>
<html lang="en">
  
<!-- Mirrored from www.crowdai.org/participants/qinyongliang by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Oct 2019 06:51:33 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <title>crowdAI</title>
    <meta name="description" content="Fighting for Open Science with Open Data">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Facebook Open Graph data -->
    <meta property="og:title" content="crowdAI" />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="qinyongliang.html" />
    <meta property="og:image" content="../../d1u1amw606tzwl.cloudfront.net/assets/misc/crowdai-head-ea7fded0f7e7e11b446f4d80f8d663b2e60fdd06546dd72be81fd978422a0725.png" />
    <meta property="og:description" content="Fighting for Open Science with Open Data" />
    <meta property="og:site_name" content="crowdAI" />

    <!-- Twitter Card data -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@crowd_ai">
    <meta name="twitter:title" content="crowdAI">
    <meta name="twitter:description" content="Fighting for Open Science with Open Data">
    <meta name="twitter:creator" content="@crowd_ai">
    <meta name="twitter:image:src" content="../../d1u1amw606tzwl.cloudfront.net/assets/misc/crowdai-head-ea7fded0f7e7e11b446f4d80f8d663b2e60fdd06546dd72be81fd978422a0725.png">

    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-57x57-5f11dd362820389c669093ea0070a5a8f98e1128c84ab5c9316768989c488d9e.png" sizes="57x57" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-60x60-a3ba860c24da457ef8f16d9d7e40814c6835bfef7268781eb17dfa1c03be83ed.png" sizes="60x60" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-72x72-fa968c8656c46df290ed1ae5dd4bb65c429b015a661330a3623b096c6e4d253e.png" sizes="72x72" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-76x76-5760f720632f080ba32a6afa52c2e48600d0fbb270f3a56d66947b6500cca3ba.png" sizes="76x76" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-114x114-ffef2a7294e6e9c95b42e0e97c52103e350dd25a76094d73a107dacbb5580249.png" sizes="114x114" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-120x120-aaddb625e759aeeaa326652d0e6ae80250ce6cc76e86cd14825af710cf7ff90f.png" sizes="120x120" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-144x144-28f2bdfee1a11984ba0dd2da8e2fcd52fc6cd6350ccafb5512fa521f40f4de8b.png" sizes="144x144" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-152x152-c42809322fa9f13067d094364700ca5b8ce238063dfc6d9d37609ba9428725c7.png" sizes="152x152" />
    <link rel="shortcut icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-180x180-6dcbd672f0ef87c1cd1b470dc1417ca1cac6c16e1443fbde7e03250f6deebada.png" sizes="192x192" />
    <link rel="shortcut icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/favicon-32x32-31fa8e51ed4c803d20eab56262d765c013deaefab71bdcdeaae2b83fb4461a9b.png" sizes="32x32" />
    <link rel="shortcut icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/favicon-96x96-7159cc97f7b1ef5b332d1384cf0fbf500c11886ed7bd743daab632d1aae80d79.png" sizes="96x96" />
    <link rel="shortcut icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/favicon-16x16-1526730d30e191cb84bd66a08d29d01165d2074733a361550afecc5edd2fd22e.png" sizes="16x16" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-57x57-5f11dd362820389c669093ea0070a5a8f98e1128c84ab5c9316768989c488d9e.png" sizes="57x57" />
    <link rel="apple-touch-icon" type="image/png" href="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/apple-icon-57x57-5f11dd362820389c669093ea0070a5a8f98e1128c84ab5c9316768989c488d9e.png" sizes="57x57" />
    <link rel="manifest" href="https://d1u1amw606tzwl.cloudfront.net/assets/favicon/manifest-e95672d4553092f574d19ee4bf1d17197b734d61b67a30e5463c91fd875095d4.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="../../d1u1amw606tzwl.cloudfront.net/assets/favicon/ms-icon-144x144-28f2bdfee1a11984ba0dd2da8e2fcd52fc6cd6350ccafb5512fa521f40f4de8b.png">
    <meta name="theme-color" content="#ffffff">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:700|Roboto:400,400i,500,500i,700" rel="stylesheet">
    <script src="../../use.fontawesome.com/bee91422da.js"></script>
        <script data-turbolinks-eval="false">
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      },
      i[r].l = 1 * new Date();
      a = s.createElement(o),
      m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '../../www.google-analytics.com/analytics.js', 'ga');
      ga('create', 'UA-75263739-1', 'auto', {'allowLinker': true });
    ga('require', 'linker');
    ga('linker:autoLink', ['crowdai.org']);
  </script>

      <script>
var _rollbarConfig = {
    accessToken: "56bdb20b34b040159a0f2c4e29eb39bb",
    captureUncaught: true,
    captureUnhandledRejections: true,
    payload: {
        environment: "production"
    }
};
// Rollbar Snippet
!function(r){function o(e){if(n[e])return n[e].exports;var t=n[e]={exports:{},id:e,loaded:!1};return r[e].call(t.exports,t,t.exports,o),t.loaded=!0,t.exports}var n={};return o.m=r,o.c=n,o.p="",o(0)}([function(r,o,n){"use strict";var e=n(1),t=n(4);_rollbarConfig=_rollbarConfig||{},_rollbarConfig.rollbarJsUrl=_rollbarConfig.rollbarJsUrl||"https://cdnjs.cloudflare.com/ajax/libs/rollbar.js/2.0.1/rollbar.min.js",_rollbarConfig.async=void 0===_rollbarConfig.async||_rollbarConfig.async;var a=e.setupShim(window,_rollbarConfig),l=t(_rollbarConfig);window.rollbar=e.Rollbar,a.loadFull(window,document,!_rollbarConfig.async,_rollbarConfig,l)},function(r,o,n){"use strict";function e(r){return function(){try{return r.apply(this,arguments)}catch(o){try{console.error("[Rollbar]: Internal error",o)}catch(n){}}}}function t(r,o){this.options=r,this._rollbarOldOnError=null;var n=s++;this.shimId=function(){return n},window&&window._rollbarShims&&(window._rollbarShims[n]={handler:o,messages:[]})}function a(r,o){var n=o.globalAlias||"Rollbar";if("object"==typeof r[n])return r[n];r._rollbarShims={},r._rollbarWrappedError=null;var t=new p(o);return e(function(){return o.captureUncaught&&(t._rollbarOldOnError=r.onerror,i.captureUncaughtExceptions(r,t),i.wrapGlobals(r,t)),o.captureUnhandledRejections&&i.captureUnhandledRejections(r,t),r[n]=t,t})()}function l(r){return e(function(){var o=this,n=Array.prototype.slice.call(arguments,0),e={shim:o,method:r,args:n,ts:new Date};window._rollbarShims[this.shimId()].messages.push(e)})}var i=n(2),s=0,c=n(3),d=function(r,o){return new t(r,o)},p=c.bind(null,d);t.prototype.loadFull=function(r,o,n,t,a){var l=function(){var o;if(void 0===r._rollbarDidLoad){o=new Error("rollbar.js did not load");for(var n,e,t,l,i=0;n=r._rollbarShims[i++];)for(n=n.messages||[];e=n.shift();)for(t=e.args||[],i=0;i<t.length;++i)if(l=t[i],"function"==typeof l){l(o);break}}"function"==typeof a&&a(o)},i=!1,s=o.createElement("script"),c=o.getElementsByTagName("script")[0],d=c.parentNode;s.crossOrigin="",s.src=t.rollbarJsUrl,n||(s.async=!0),s.onload=s.onreadystatechange=e(function(){if(!(i||this.readyState&&"loaded"!==this.readyState&&"complete"!==this.readyState)){s.onload=s.onreadystatechange=null;try{d.removeChild(s)}catch(r){}i=!0,l()}}),d.insertBefore(s,c)},t.prototype.wrap=function(r,o){try{var n;if(n="function"==typeof o?o:function(){return o||{}},"function"!=typeof r)return r;if(r._isWrap)return r;if(!r._wrapped){r._wrapped=function(){try{return r.apply(this,arguments)}catch(o){var e=o;throw"string"==typeof e&&(e=new String(e)),e._rollbarContext=n()||{},e._rollbarContext._wrappedSource=r.toString(),window._rollbarWrappedError=e,e}},r._wrapped._isWrap=!0;for(var e in r)r.hasOwnProperty(e)&&(r._wrapped[e]=r[e])}return r._wrapped}catch(t){return r}};for(var u="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection".split(","),f=0;f<u.length;++f)t.prototype[u[f]]=l(u[f]);r.exports={setupShim:a,Rollbar:p}},function(r,o){"use strict";function n(r,o){if(r){var n;"function"==typeof o._rollbarOldOnError?n=o._rollbarOldOnError:r.onerror&&!r.onerror.belongsToRollbar&&(n=r.onerror,o._rollbarOldOnError=n);var t=function(){var t=Array.prototype.slice.call(arguments,0);e(r,o,n,t)};t.belongsToRollbar=!0,r.onerror=t}}function e(r,o,n,e){r._rollbarWrappedError&&(e[4]||(e[4]=r._rollbarWrappedError),e[5]||(e[5]=r._rollbarWrappedError._rollbarContext),r._rollbarWrappedError=null),o.handleUncaughtException.apply(o,e),n&&n.apply(r,e)}function t(r,o){if(r){"function"==typeof r._rollbarURH&&r.removeEventListener("unhandledrejection",r._rollbarURH);var n=function(r){var n=r.reason,e=r.promise,t=r.detail;!n&&t&&(n=t.reason,e=t.promise),o&&o.handleUnhandledRejection&&o.handleUnhandledRejection(n,e)};r._rollbarURH=n,r.addEventListener("unhandledrejection",n)}}function a(r,o){if(r){var n,e,t="EventTarget,Window,Node,ApplicationCache,AudioTrackList,ChannelMergerNode,CryptoOperation,EventSource,FileReader,HTMLUnknownElement,IDBDatabase,IDBRequest,IDBTransaction,KeyOperation,MediaController,MessagePort,ModalWindow,Notification,SVGElementInstance,Screen,TextTrack,TextTrackCue,TextTrackList,WebSocket,WebSocketWorker,Worker,XMLHttpRequest,XMLHttpRequestEventTarget,XMLHttpRequestUpload".split(",");for(n=0;n<t.length;++n)e=t[n],r[e]&&r[e].prototype&&l(o,r[e].prototype)}}function l(r,o){if(o.hasOwnProperty&&o.hasOwnProperty("addEventListener")){var n=o.addEventListener;n._rollbarOldAdd&&(n=n._rollbarOldAdd);var e=function(o,e,t){n.call(this,o,r.wrap(e),t)};e._rollbarOldAdd=n,o.addEventListener=e;var t=o.removeEventListener;t._rollbarOldRemove&&(t=t._rollbarOldRemove);var a=function(r,o,n){t.call(this,r,o&&o._wrapped||o,n)};a._rollbarOldRemove=t,o.removeEventListener=a}}r.exports={captureUncaughtExceptions:n,captureUnhandledRejections:t,wrapGlobals:a}},function(r,o){"use strict";function n(r,o){this.impl=r(o,this),this.options=o,e(n.prototype)}function e(r){for(var o=function(r){return function(){var o=Array.prototype.slice.call(arguments,0);if(this.impl[r])return this.impl[r].apply(this.impl,o)}},n="log,debug,info,warn,warning,error,critical,global,configure,handleUncaughtException,handleUnhandledRejection,_createItem,wrap,loadFull,shimId".split(","),e=0;e<n.length;e++)r[n[e]]=o(n[e])}n.prototype._swapAndProcessMessages=function(r,o){this.impl=r(this.options);for(var n,e,t;n=o.shift();)e=n.method,t=n.args,this[e]&&"function"==typeof this[e]&&this[e].apply(this,t);return this},r.exports=n},function(r,o){"use strict";r.exports=function(r){return function(o){if(!o&&!window._rollbarInitialized){r=r||{};for(var n,e,t=r.globalAlias||"Rollbar",a=window.rollbar,l=function(r){return new a(r)},i=0;n=window._rollbarShims[i++];)e||(e=n.handler),n.handler._swapAndProcessMessages(l,n.messages);window[t]=e,window._rollbarInitialized=!0}}}}]);
// End Rollbar Snippet
</script>

    <link rel="stylesheet" media="all" href="../../d1u1amw606tzwl.cloudfront.net/assets/application-fbad2a77a3c16168d762d7bcd70b51933687bf62defed75590da7d06afb9c181.css" data-turbolinks-track="true" />
    <script src="../../d1u1amw606tzwl.cloudfront.net/assets/application-7d73590a8408508da67ef02bc6ff6e8dcdd86d359df9bb543dd538d7a9411554.js" data-turbolinks-track="true"></script>
    <meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="eONw+DludGithG/C7aHaOOpTlzIUGcER/Zei2DG3gUephIuid6fndHunGdVJg41hSQ+ownzQJ1dCxkGCHssBug==" />
    <script src="../../d1u1amw606tzwl.cloudfront.net/packs/application-0a6ea7b74599e58741ff.js"></script>
    <link rel="stylesheet" media="screen" href="../../d1u1amw606tzwl.cloudfront.net/packs/application-a4f1ebb6e6bc4a2b9e31.css" />
  </head>

  <body id=''>
    <!-- loader container -->
  <div id='loader-container' class="loader-container">

    <!-- loader -->
    <div class="loader" title="0">
      <svg version="1.1" id="loader-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="40px" height="40px" viewBox="0 0 40 40" enable-background="new 0 0 40 40" xml:space="preserve">
        <path opacity="0.2" fill="#F0514D" d="M20.201,5.169c-8.254,0-14.946,6.692-14.946,14.946c0,8.255,6.692,14.946,14.946,14.946s14.946-6.691,14.946-14.946C35.146,11.861,28.455,5.169,20.201,5.169z M20.201,31.749c-6.425,0-11.634-5.208-11.634-11.634c0-6.425,5.209-11.634,11.634-11.634c6.425,0,11.633,5.209,11.633,11.634C31.834,26.541,26.626,31.749,20.201,31.749z"/>
        <path fill="#F0514D" d="M26.013,10.047l1.654-2.866c-2.198-1.272-4.743-2.012-7.466-2.012h0v3.312h0C22.32,8.481,24.301,9.057,26.013,10.047z">
        <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 20 20" to="360 20 20" dur="0.5s" repeatCount="indefinite"/>
        </path>
      </svg>
      <br>
      <span>Loading</span>
    </div>
    <!-- loader -->

  </div>
  <!-- /loader container -->

    <div id='page-content'>
      <header>
  <div class="row">
    <div class="branding">
      <a class="logo" href="../index.html" title=""></a>
    </div>
    <nav class="primary">
      <ul>
        <li><a href="../challenges.html">Challenges</a></li>
        <li><a href="../articles.html">Knowledge Base</a></li>
        <li><a href="../job_postings.html">Job Board</a></li>
          <li><a href="sign_in.html">Log in</a></li>
      </ul>
    </nav>
    <div class="menu">
      <a id="mobile-nav" href="#">
        <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
      </a>
    </div>
  </div>
  <nav class="mobile-primary">
    <div id="mobile-nav-header">
      <div class="row">
        <a class="logo" href="#" title=""></a>
        <a id="mobile-nav" href="#">
          <i class="fa fa-times fa-lg" aria-hidden="true"></i>
        </a>
      </div>
    </div>
    <ul>
      <li><h3><a href="../challenges.html">Challenges</a></h3></li>
      <li><h3><a href="../articles.html">Knowledge Base</a></h3></li>
      <li><h3><a href="../job_postings.html">Job Board</a></h3></li>
    </ul>
      <ul>
        <li>
          <h4><a href="sign_in.html">Log in</a></h4>
        </li>
      </ul>
  </nav>
    <div class="cookies-eu js-cookies-eu">
    <span class="cookies-eu-content-holder">Cookies help us deliver our services. By using our services, you agree to our use of cookies.</span>
    <span class="cookies-eu-button-holder">
      <button class="btn btn-primary cookies-eu-ok js-cookies-eu-ok"> OK </button>
      <a href="../cookies.html" class=" btn cookies-eu-link" target="_blank"> Learn more </a>
    </span>
  </div>

</header>

      <div id='flash-messages'>
</div>

      <div class="site-message">
  <div class="row">
    <p>crowdAI is shutting down - please read our <a href="../blogs/7.html">blog post</a> for more information
  </div>
</div>

      <div class='content'>
  <div class="masthead-detailed">
  <div class="row">
    <div class="pic pic-user">
      <img src="../../dnczkxd1gcfu5.cloudfront.net/images/participants/image_file/1250/umaru_chem_square236px.png" />    </div>
    <div class="info info-user">
      <div class="heading-w-icon">
        <h2>QinYongliang</h2>
              </div>
            <div class="text-w-icon">
              </div>
      <ul class="social-links">
                  <li><a href="https://github.com/ctmakro"><i class="fa fa-github" aria-hidden="true"></i></a></li>
                  <li><a href="https://ctmakro.github.io/site"><i class="fa fa-link" aria-hidden="true"></i></a></li>
              </ul>
          </div>
  </div>
</div>


  <div class="sub-nav">
    <div class="row">
      <ul class='tabs'>
        <li data-tab='tab-challenges' class="active">
          <a href="#" onclick="return false;">Challenges
            <sup>4</sup>
          </a>
        </li>
        <li data-tab='tab-articles'>
          <a href="#" onclick="return false;">Tutorials
            <sup></sup>
          </a>
        </li>
        <li data-tab='tab-posts'>
          <a href="#" onclick="return false;">Posts
            <sup>19</sup>
          </a>
        </li>
        <li data-tab='tab-bio'>
          <a href="#" onclick="return false;">Bio</a>
        </li>
      </ul>
    </div>
  </div>

  <div id='tab-challenges' class='tab-content active'>
    <div class="row">
      <ul class="list-challenges">
        <li data-cell='Challenge::Cell::ListDetail'>
  <div class="pic">
    <a href="../challenges/mapping-challenge.html"><img src="../../dnczkxd1gcfu5.cloudfront.net/images/challenges/image_file/25/mapping_challenge_1.jpg" /></a>  </div>
  <div class="details">
    <h5 class="ellipsis"><a href="../challenges/mapping-challenge.html">Mapping Challenge</a></h5>
    <p class="description ellipsis">Building Missing Maps with Machine Learning</p>
    <p class="status active">Challenge ended</p>
  </div>
  <div class="stats">
    <div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  719<br>
  <span>Submissions</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  1068<br>
  <span>Participants</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  42.5 k<br>
  <span>Views</span>
</div>
  </div>
</li>
<li data-cell='Challenge::Cell::ListDetail'>
  <div class="pic">
    <a href="../challenges/ai-generated-music-challenge.html"><img src="../../dnczkxd1gcfu5.cloudfront.net/images/challenges/image_file/12/Screen_Shot_2017-11-04_at_10.32.55.png" /></a>  </div>
  <div class="details">
    <h5 class="ellipsis"><a href="../challenges/ai-generated-music-challenge.html">AI-generated music challenge</a></h5>
    <p class="description ellipsis">Music generated by AI </p>
    <p class="status active">Challenge ended</p>
  </div>
  <div class="stats">
    <div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  111<br>
  <span>Submissions</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  182<br>
  <span>Participants</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  19.3 k<br>
  <span>Views</span>
</div>
  </div>
</li>
<li data-cell='Challenge::Cell::ListDetail'>
  <div class="pic">
    <a href="../challenges/nips-17-workshop-criteo-ad-placement-challenge.html"><img src="../../dnczkxd1gcfu5.cloudfront.net/images/challenges/image_file/11/multiarmedbandit.jpg" /></a>  </div>
  <div class="details">
    <h5 class="ellipsis"><a href="../challenges/nips-17-workshop-criteo-ad-placement-challenge.html">NIPS '17 Workshop: Criteo Ad Placement Challenge</a></h5>
    <p class="description ellipsis">Counterfactual policy learning for display advertising</p>
    <p class="status active">Challenge ended</p>
  </div>
  <div class="stats">
    <div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  246<br>
  <span>Submissions</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  181<br>
  <span>Participants</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  11.8 k<br>
  <span>Views</span>
</div>
  </div>
</li>
<li data-cell='Challenge::Cell::ListDetail'>
  <div class="pic">
    <a href="../challenges/nips-2017-learning-to-run.html"><img src="../../dnczkxd1gcfu5.cloudfront.net/images/challenges/image_file/8/8.Screen_Shot_2017-04-10_at_1.23.56_PM.png" /></a>  </div>
  <div class="details">
    <h5 class="ellipsis"><a href="../challenges/nips-2017-learning-to-run.html">NIPS 2017: Learning to Run</a></h5>
    <p class="description ellipsis">Reinforcement learning environments with musculoskeletal models</p>
    <p class="status active">Challenge ended</p>
  </div>
  <div class="stats">
    <div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  2154<br>
  <span>Submissions</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  631<br>
  <span>Participants</span>
</div>
<div class="stat-fr" data-cell='Challenge::Cell::Statistic'>
  91.1 k<br>
  <span>Views</span>
</div>
  </div>
</li>

      </ul>
    </div>
  </div>

  <div id='tab-articles' class='tab-content'>
    <div class="row">
        <div class='article'>
          <p class='light'>
            QinYongliang hasn&#39;t authored any tutorials yet...
          </p>
        </div>
    </div>
  </div>

  <div id='tab-posts' class='tab-content'>
    <div class="row">
      <ul class="list-tutorials">
        <div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/official-results-we-have-a-winner/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Official Results :: We have a winner !! |&nbsp; almost 2 years ago
      </p>
      <div class='comment' id='comment_573'
        <p><p>This announcement is so official, that I think I should first appreciate the hard work the developers/organizers have gone through, then name a few institutions that supported this with abundant resources, and finally express gratitude to the honorable invitation.</p>

<p>Yea but let’s not forget those who spent their time to make the competition meaningful - without all those hundreds of participants’ efforts, we won’t be able to confirm/conclude that the winning entry is indeed the state-of-the-art. It’s those who didn’t receive the prize made the prize heavier.</p>

<p>I’d like to mention a few of them in acknowledgment, the Chinese speaking participants in particular:</p>

<ul>
  <li>USTC-ICML (USTC</li>
  <li>hzwer (PKU</li>
  <li>JGeek (THU</li>
  <li>J1 (UIUC</li>
  <li>SDU_VSIS (SDU</li>
  <li>Yujin</li>
  <li>VsonicV</li>
</ul>

<p>Greatest respect for them and all other participants.</p>
</p>
      </div>
      <a id="vote-link-comment-573" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i>  1</a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/osimenv-gets-stuck-on-a-particular-step-for-a-long-time/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        OsimEnv gets stuck on a particular step for a long time |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_376'
        <p><p>this is totally normal, for a constant accuracy solver. and yes, when forces are strong and nonlinear, longer time is needed per step.</p>

<p>very occasionally you will experience 5-10 minutes per step. There’s no way around it, except lower the accuracy, which can be done by modifying C source of opensim.</p>
</p>
      </div>
      <a id="vote-link-comment-376" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_371'
        <p><blockquote>
  <p>Thanks for sharing. 
“When running at 100 fps you don’t neccessarily sample at 100 fps” -&gt; How do I change the sample from 100fps to 50 fps? I am using example.py and dont see any place where this is being set.</p>
</blockquote>

<p>you should not change the environment itself, but you can wrap it up with your code :)</p>
</p>
      </div>
      <a id="vote-link-comment-371" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/import-failure-on-aws-on-both-ubuntu-14-04-and-16-04-after-following-the-exact-instruction-of-installation/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Import failure on AWS on both ubuntu 14.04 and 16.04, after following the exact instruction of installation |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_370'
        <p><p>seems that lapack is missing.</p>
</p>
      </div>
      <a id="vote-link-comment-370" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/credits-in-aws-account/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Credits in AWS account |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_356'
        <p><p>I already received my credit. But to create more than a few machines, you will need to ask AWS to raise the service limit for you.</p>
</p>
      </div>
      <a id="vote-link-comment-356" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/how-are-the-hopper-models-working/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        How are the hopper models working?  |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_347'
        <p><p>TRPO guarantees monotonical improvement over training episodes; It’s less related to human reinforcement learning but more related to numerical optimization. As for now, we still can’t be sure a hopping policy will eventually beat all those running policy.</p>

<p>There’s one detail I’ve mentioned before on Github: since the environment limits the agent from tilting to the side by restricting the body in the x-y plane, it might actually be better for the agent to hop than to run. comparing to DeepMind’s walking agent’s DoFs, our competition is actually only a subset of it.</p>
</p>
      </div>
      <a id="vote-link-comment-347" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/how-are-the-hopper-models-working/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        How are the hopper models working?  |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_346'
        <p><p>TRPO is a policy searcher. The search is done via line search instead of random exploration. Therefore, since the environment has a pretty stable initial condition(the agent always start with both legs aligned), it would result in policies as shown in jyu and spMohanty’s submission.</p>
</p>
      </div>
      <a id="vote-link-comment-346" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_345'
        <p><p>for multiprocessing, I wrote a detailed example here.</p>

<p>https://github.com/stanfordnmbl/osim-rl/issues/58</p>

<p>you should also read every issue on github about osim-rl to avoid all kinds of problems.</p>
</p>
      </div>
      <a id="vote-link-comment-345" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_339'
        <p><blockquote>
  <p>Thanks for the detailed tutorial. Can you please expand on how something like DDPG agent (from keral-rl) can be used with multiple parallel RunEnv()s?</p>
</blockquote>

<p>all those agent has a ‘play’ (or in some other names) method, that takes an environment and env.reset() then env.step() thru it. It will also sample observations and store them into the agent’s memory and perform training updates to the neural network.</p>

<p>You can create multiple threads and ask each of them to 1) obtain an environment, for example by starting one in a separate process, and 2) call the agent’s ‘play’ method with that environment as a parameter.</p>

<p>This method is quite straight-forward if you coded DDPG yourself with TF or Theano or Torch, instead of using an existing package like keras-rl. I believe most people here rely on keras-rl. From an engineering perspective, black box = failure so make your choices carefully.</p>
</p>
      </div>
      <a id="vote-link-comment-339" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i>  1</a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_336'
        <p><p>8) windows user might complain that osim-rl don’t work with Python3 on windows, yet.</p>

<p>I spent a great deal of time to make the osim-rl runnable on windows with Python3. It requires Visual C++ compilation and (possibly) alteration of source code so please don’t waste your time like I did.</p>

<p>Instead you should start the environment in Python2.7, preferably in a conda virtual environment. Then write your code in Python3, and use RPC to talk to the environment, instead of running them in the same process.</p>
</p>
      </div>
      <a id="vote-link-comment-336" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_335'
        <p><p>7) if you didn’t get the AWS credit because you didn’t join the competition early enough, and you are also not willing to pay for cloud services, there’s still hope for you.
I just stopped all my servers on Aliyun (they are expensive). At home I have 2 PCs, one with i7-3610QM, one with Pentium E5300, and an i5-based RMBP. This is 8+2+4 cores in total, so running in parallel they are only slightly slower than my 16-server(one core each) rig. 
So if you really want to walk like a human, find every piece of hardware around you that are capable of running osim-rl and connect them together. Most people here should have no difficulty getting themself 2 or 3 PCs (just ask friends or parents).</p>
</p>
      </div>
      <a id="vote-link-comment-335" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_333'
        <p><p>6) and of course, noise.
In DRL, there are two types of algorithm: deterministic and probalistic. They are designed to deal with deter- and proba- environments. If the space of actions an agent could take consists of a set of choices, and the agent has to choose one of the actions to take per step, then this environment is probalistic.</p>

<p>For a proba- environment, you can train a neural network to fit the distribution of reward over the choices, given the state; then you can sample actions according to the distribution, given a new state. DQN is one such algorithm, and it’s one of the easiest DRL algorithm to understand. Deep Policy Gradient is even simpler than DQN, but DQN worked way better due to its more clever action sampling method.</p>

<p>But this “learning to run” thing, is deterministic and continuous, meaning that instead of making discrete choices, you will have to output a list of real values as your action per step. You can still fit a distribution of reward over a continuum of choices, by using mixture of gaussians blah blah, and you can of course sample from such a distribution. Doing so results in the CDQN algorithm, which means Continuous space DQN.</p>

<p>While CDQN is cool, it’s not the simplest, and require extensive knowledge in probalistics; the simplest deter- algorithm would be DDPG, or Deep Deteministic Policy Gradient.</p>

<p>In DQN we randomly sample the choices using a multinoulli distribution, as a means of exploration, because you have to make mistakes first, then learn from them. in an deter- algorithm like DDPG, exploration is achieved by adding noise to the action values. Details are in the DDPG paper.</p>

<p>So if you choose DDPG, noise is a very important hyperparameter. The more noise we add, the more different situations our agent will run into; but the agent will also fail more often. When the learning stops to progress, it is very likely that your exploration noise is too low. Tune that up a bit and see if it improves.</p>
</p>
      </div>
      <a id="vote-link-comment-333" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i>  3</a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/tutorial-getting-the-skeleton-to-walk/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Tutorial: Getting the skeleton to walk |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_331'
        <p><p>36 days to go, if you still can’t get your skeleton to walk, this might help.</p>

<p>1) 
To succesfully walk, you train a neural network which maps states to actions that maximizes the Expected Future Reward. If you already learned a little bit about Deep Reinforcement Learning, you know what I’m talking about. You can use an out-of-the-box DRL algorithm for this task, such as DDPG.</p>

<p>Problem is, the observation vector (41 dimensions) is just an OBSERVATION, not STATE. A state should be markovian, which means from a state you must be able to predict what happens next, or estimate what reward you get after, given certain actions. Which is basically what your learning algorithm, say DDPG, is trying to do.</p>

<p>The observation vector is not markovian. For example, since the velocity of your agent’s head is not in the observation vector, the agent won’t be able to know which way his head is currently leaning forward, therefore couldn’t make the right judgement of muscle actions to balance himself. As a result, the agent will walk poorly.</p>

<p>To make the observation vector markovian, you can either:</p>

<p>a) calculate velocities of all the body parts: v = dx/dt = (x_now - x_last)/0.01 and add them to your observation vector, then feed to your learning algorithm.</p>

<p>b) concatenate two consecutive observations into one and use that as your observation vector, then expect the neural network to do the dx/dt calculation for you.</p>

<p>simply choose option a), set your DDPG algorithm’s gamma value to 0.995 (~200 steps or 2 seconds lookahead of future reward estimation) and run your agent for ~10000 episodes, should result in a not-too-bad score.</p>

<p>2)
When running at 100 fps you don’t neccessarily sample at 100 fps. At 100fps your past experience memory will very soon be filled with observations; but since they are sampled at 100fps, they are quite correlated to each other. Sample experiences at a rate lower than 100fps, say 50fps or 33fps, will improve the agent’s ability to learn, since your memory now contains experiences with higher variety and less correlation.</p>

<p>3) in DDPG for example, you ask the agent to train itself per act, which means 100 fps. You might be interested in training at 200fps.</p>

<p>4)
When designing the network topology, keep in mind that:</p>

<p>Your objective is to maximize an “expected future reward” by learning from past experience. Since “past experience” is changing over time, your learning objective, from the neural network perspective, is also changing over time. Therefore your network must be very well suited to this adaptive process, or “malleable” or “retrainable”. In other words, if your network cannot be retrained for other purposes once it’s trained for some purpose, then it should not be used here.</p>

<p>It is thus recommended to use shallow and wide topology, rather than deep and narrow ones. Don’t waste time on residual connections. Don’t use tanh or sigmoid units (except at output layer).</p>

<p>For rectifiers, personally I use LeakyReLU, because they don’t kill the gradients like ReLUs.</p>

<p>5) 
You soon realized that you simply can’t run the environment for 10000 episodes.</p>

<p>a) memory leaks destroyed your environment.
solution: start RunEnv() in a separate process and talk to that process. After ~100 episodes, kill that process and start a new one.
Don’t start RunEnv() in a separate thread; The RunEnv() will invoke the same instance OpenSim backend, result in no protection of memory leaks.</p>

<p>b) the environment is running at ~1 to 3 fps, thus takes forever.
solution: start 16 RunEnv() as described above and run them in parallel. Sample the actions and reward in parallel. Put a threading.Lock on the agent’s memory to prevent conflicts. This requires knowledge in Operating System’s Threads/Processes/Locks, and I suggest the corresponding course by UCB on YouTube.</p>

<p>c) you don’t have 16 cores.
solution: start the RunEnv()s on mutiple AWS instances and train with them by doing RPCs. This requires knowledge in Network Communication, Udacity/Coursera/YouTube is the place to go. Python users should try the Pyro4 library.</p>

<p>I’m currently in China, so I bought 16 servers on Aliyun (the equivalent of AWS in China). This way I managed to train my agent to get an average score of 16.9 points.</p>

<p>Goodluck everyone.</p>
</p>
      </div>
      <a id="vote-link-comment-331" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/video-clips-on-the-leaderboard-feels-foreign/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Video clips on the leaderboard feels foreign |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_330'
        <p><p>after reading the code, I found the problem:
https://github.com/kidzik/osim-rl-grader/blob/master/worker_dir/simulate.py#L32-L34</p>

<p>this is unacceptable, since you assume the intergrator of the simulator is PERFECT with UNLIMITED ACCURACY. as an amateur computer scientist, I know this is clearly not true.</p>

<p>I’ll file an issue on the repo.</p>
</p>
      </div>
      <a id="vote-link-comment-330" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/video-clips-on-the-leaderboard-feels-foreign/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Video clips on the leaderboard feels foreign |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_328'
        <p><p>@spMohanty I know this part very well. However, the fact is that I accumulated the total reward of all 3 submission on the client side while submitting. they are all greater than 15.</p>

<p>And it’s not just me; everybody on the top of the chart, their submission seemed very wrong. If they scored, as the video suggested, say 5-7 points in the first trial, it would not be possible to average it out and score &gt;15 points in the next two trials.</p>

<p>And from the video you can see that, the specific seeded trial is rather easy (with very small obstacles), and the agents all performed stupidly.</p>

<p>From my 10+ years of experience of programming, this is definitely a bug. The ids of the videos must have been messed up.</p>
</p>
      </div>
      <a id="vote-link-comment-328" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/video-clips-on-the-leaderboard-feels-foreign/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        Video clips on the leaderboard feels foreign |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_321'
        <p><p>on latest submission i scored &gt;15 points each run. but the leaderboard video is showing me falling to the ground. shouldn’t it be a bug or something?</p>
</p>
      </div>
      <a id="vote-link-comment-321" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/how-performant-is-the-submission-server/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        How performant is the submission server? |&nbsp; about 2 years ago
      </p>
      <div class='comment' id='comment_261'
        <p><p>will it be crowded with submission runs, such that individual submission become slow?</p>
</p>
      </div>
      <a id="vote-link-comment-261" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/training-episodes-is-now-of-length-1000-timesteps-is-server-evaluation-still-500-episodes/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        training episodes is now of length 1000 timesteps. is server evaluation still 500 episodes? |&nbsp; over 2 years ago
      </p>
      <div class='comment' id='comment_210'
        <p><p>TYPO:
-  is server evaluation still 500 timesteps?</p>

<p>because agents trained for 1000 timesteps will not perform well in 500 timesteps setting (he will not jump forward during the last few timesteps)</p>
</p>
      </div>
      <a id="vote-link-comment-210" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i>  1</a></a>  </div>
</div>
<div class="discussion-comment" data-cell='Discussion::Cell::ParticipantComment'>
  <div class="topic-content">
    <a href="../topics/training-episodes-is-now-of-length-1000-timesteps-is-server-evaluation-still-500-episodes/comments/new.html">      <p class="details">
        NIPS 2017: Learning to Run |&nbsp;
        training episodes is now of length 1000 timesteps. is server evaluation still 500 episodes? |&nbsp; over 2 years ago
      </p>
      <div class='comment' id='comment_209'
        <p><p>besides that, what else is different between training and evaluation environment?</p>
</p>
      </div>
      <a id="vote-link-comment-209" class="btn btn-secondary" href="sign_in.html"><i class='fa fa-heart' aria-hidden='true'></i> </a></a>  </div>
</div>

      </ul>
    </div>
  </div>

  <div id='tab-bio' class='tab-content'>
    <div class="row">
      <div class="article">
        BSc Power System Engineering;
10 yr programmer;
Author of pip install canton;
https://ctmakro.github.io/resume;
ctmakro@gmail.com
      </div>
    </div>
  </div>



</div><!-- .content -->

      
<div class="js-paloma-hook" data-palomaid="1571809796654">
  <script type="text/javascript">
    (function(){

      if ( !window['Paloma'] ) return true;
      Paloma.env = 'production';

      var id = "1571809796654",
          request = {"resource":"Participants","action":"show","params":{}};

      Paloma.engine.setRequest({
        id: id,
        resource: request.resource,
        action: request.action,
        params: request.params
      });

      var self  = document.querySelector("[data-palomaid='" + id + "']");
      if (self) self.parentNode.removeChild(self);

    })();
  </script>
</div>

      <footer class="">
  <div class="row">
    <a class="logo-footer" href="http://epfl.ch/">
      <img src="../../d1u1amw606tzwl.cloudfront.net/assets/misc/EPFL_Logo_Digital_RGB_PROD-60bb226e14e8a37db07793a88a44ce5fe4dfa7f23bc8bab21a52c8664e26b8ab.png" />
    </a>
    <p class="copyright">&#9400; 2018 crowdAI</p>
    <ul class="social">
      <li>
        <a href="https://twitter.com/crowd_ai">
          <i class="fa fa-twitter fa-lg" aria-hidden="true"></i>
        </a>
      </li>
      <li>
        <a href="https://github.com/crowdAI">
          <i class="fa fa-github fa-lg" aria-hidden="true"></i>
        </a>
      </li>
    </ul>
    <ul class="links">
      <li><a href="../faq.html">FAQ</a></li>
      <li><a href="../contact.html">Contact</a></li>
      <li><a href="../privacy.html">Privacy</a></li>
      <li><a href="../terms.html">Terms of Service</a></li>
      <li><a href="../cookies.html">Cookie consent</a></li>
    </ul>
  </div>
</footer>

    </div>
      <script>
    ga('set', 'location', location.href.split('#')[0]);
    ga('send', 'pageview', {"title": document.title});
  </script>

  </body>

<!-- Mirrored from www.crowdai.org/participants/qinyongliang by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Oct 2019 06:51:33 GMT -->
</html>
